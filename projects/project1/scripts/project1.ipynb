{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = correction_missing_values(tX)\n",
    "tX, mean_x, std_x = standardize(tX)\n",
    "tX = normalize(tX)\n",
    "tX = np.c_[np.ones((y.shape[0], 1)), tX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from scikit learn - logistic regression: 73.94 %\n",
      "\n",
      "Accuracy from scikit learn - Support Vector Machine: 67.44 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_logistic = LogisticRegression(random_state=0).fit(tX, y)\n",
    "clf_SVC = SVC(gamma='auto').fit(tX,y)\n",
    "print(\"Accuracy from scikit learn - logistic regression: \"+str(round(100*clf_logistic.score(tX, y),5))+' %\\n')\n",
    "print(\"Accuracy from scikit learn - Support Vector Machine: \"+str(round(100*clf_SVC.score(tX, y),5))+' %\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=14330.761585035349\n",
      "Current iteration=100, loss=3101.08933151618\n",
      "Current iteration=200, loss=3057.2066610554793\n",
      "Current iteration=300, loss=3018.668010903647\n",
      "Current iteration=400, loss=2984.665806532561\n",
      "Current iteration=500, loss=2954.514071113862\n",
      "Current iteration=600, loss=2927.636595649753\n",
      "Current iteration=700, loss=2903.5524886894605\n",
      "Current iteration=800, loss=2881.861575493349\n",
      "Current iteration=900, loss=2862.2309572445456\n",
      "Current iteration=1000, loss=2844.3832756247966\n",
      "Current iteration=1100, loss=2828.0867879008238\n",
      "Current iteration=1200, loss=2813.1471359345596\n",
      "Current iteration=1300, loss=2799.4006006225713\n",
      "Current iteration=1400, loss=2786.7086114545004\n",
      "Current iteration=1500, loss=2774.953293163591\n",
      "Current iteration=1600, loss=2764.033857751266\n",
      "Current iteration=1700, loss=2753.8636800668914\n",
      "Current iteration=1800, loss=2744.367923643686\n",
      "Current iteration=1900, loss=2735.4816086012897\n",
      "Current iteration=2000, loss=2727.148034588775\n",
      "Current iteration=2100, loss=2719.3174891256895\n",
      "Current iteration=2200, loss=2711.946185754953\n",
      "Current iteration=2300, loss=2704.9953876783984\n",
      "Current iteration=2400, loss=2698.430681509638\n",
      "Current iteration=2500, loss=2692.221372895263\n",
      "Current iteration=2600, loss=2686.3399813978167\n",
      "Current iteration=2700, loss=2680.761816508146\n",
      "Current iteration=2800, loss=2675.464620205376\n",
      "Current iteration=2900, loss=2670.428264305272\n",
      "Current iteration=3000, loss=2665.634493085504\n",
      "Current iteration=3100, loss=2661.0667034707826\n",
      "Current iteration=3200, loss=2656.7097564967385\n",
      "Current iteration=3300, loss=2652.5498149235855\n",
      "Current iteration=3400, loss=2648.5742027975575\n",
      "Current iteration=3500, loss=2644.7712835060884\n",
      "Current iteration=3600, loss=2641.1303534776885\n",
      "Current iteration=3700, loss=2637.6415491686594\n",
      "Current iteration=3800, loss=2634.295765378225\n",
      "Current iteration=3900, loss=2631.0845832599734\n",
      "Current iteration=4000, loss=2628.000206664319\n",
      "Current iteration=4100, loss=2625.0354056660917\n",
      "Current iteration=4200, loss=2622.1834663118134\n",
      "Current iteration=4300, loss=2619.4381457704185\n",
      "Current iteration=4400, loss=2616.793632194851\n",
      "Current iteration=4500, loss=2614.2445087046635\n",
      "Current iteration=4600, loss=2611.785720985593\n",
      "Current iteration=4700, loss=2609.412548073733\n",
      "Current iteration=4800, loss=2607.1205759522336\n",
      "Current iteration=4900, loss=2604.9056736391567\n",
      "Current iteration=5000, loss=2602.763971488051\n",
      "Current iteration=5100, loss=2600.691841459163\n",
      "Current iteration=5200, loss=2598.6858791501368\n",
      "Current iteration=5300, loss=2596.7428874015322\n",
      "Current iteration=5400, loss=2594.8598613150816\n",
      "Current iteration=5500, loss=2593.0339745420806\n",
      "Current iteration=5600, loss=2591.262566716052\n",
      "Current iteration=5700, loss=2589.5431319183845\n",
      "Current iteration=5800, loss=2587.8733080781403\n",
      "Current iteration=5900, loss=2586.2508672182576\n",
      "Current iteration=6000, loss=2584.673706469881\n",
      "Current iteration=6100, loss=2583.139839784877\n",
      "Current iteration=6200, loss=2581.6473902840435\n",
      "Current iteration=6300, loss=2580.1945831848143\n",
      "Current iteration=6400, loss=2578.7797392580737\n",
      "Current iteration=6500, loss=2577.4012687686736\n",
      "Current iteration=6600, loss=2576.0576658586933\n",
      "Current iteration=6700, loss=2574.747503336483\n",
      "Current iteration=6800, loss=2573.469427837992\n",
      "Current iteration=6900, loss=2572.222155330067\n",
      "Current iteration=7000, loss=2571.004466928245\n",
      "Current iteration=7100, loss=2569.8152050039535\n",
      "Current iteration=7200, loss=2568.653269558435\n",
      "Current iteration=7300, loss=2567.517614842619\n",
      "Current iteration=7400, loss=2566.407246204062\n",
      "Current iteration=7500, loss=2565.321217143658\n",
      "Current iteration=7600, loss=2564.258626566346\n",
      "Current iteration=7700, loss=2563.218616211362\n",
      "Current iteration=7800, loss=2562.200368248768\n",
      "Current iteration=7900, loss=2561.2031030301546\n",
      "Current iteration=8000, loss=2560.2260769823233\n",
      "Current iteration=8100, loss=2559.268580633744\n",
      "Current iteration=8200, loss=2558.329936764312\n",
      "Current iteration=8300, loss=2557.4094986697964\n",
      "Current iteration=8400, loss=2556.5066485329185\n",
      "Current iteration=8500, loss=2555.6207958937343\n",
      "Current iteration=8600, loss=2554.7513762125136\n",
      "Current iteration=8700, loss=2553.8978495188167\n",
      "Current iteration=8800, loss=2553.05969914096\n",
      "Current iteration=8900, loss=2552.2364305105466\n",
      "Current iteration=9000, loss=2551.4275700370204\n",
      "Current iteration=9100, loss=2550.6326640477027\n",
      "Current iteration=9200, loss=2549.8512777889955\n",
      "Current iteration=9300, loss=2549.0829944848283\n",
      "Current iteration=9400, loss=2548.32741444865\n",
      "Current iteration=9500, loss=2547.584154245573\n",
      "Current iteration=9600, loss=2546.8528459014824\n",
      "Current iteration=9700, loss=2546.133136156175\n",
      "Current iteration=9800, loss=2545.4246857577623\n",
      "Current iteration=9900, loss=2544.7271687958373\n",
      "[ -2.41765218  -0.75744973 -12.16510378  -1.28714062   3.21244055\n",
      "   2.53094464   1.45091996  -2.17708871   4.65551443  -2.19685718\n",
      "   2.15133923  -4.92917587   7.12063219   4.12846012   6.39590941\n",
      "   0.66881007  -0.57950945   2.11280075   1.28077417   0.35144244\n",
      "  -0.39271042  -0.43006667   0.33986078   0.98465437  -0.37430844\n",
      "  -1.85008484  -0.70583203  -3.18931286  -0.0347067   -0.58994315\n",
      "  -0.37612086] 2544.047089466388\n",
      "Accuracy from our code:\n",
      "\n",
      "Logistic regression: 72.46 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from logistic_regression import *\n",
    "#Using our code\n",
    "\n",
    "gamma = 0.0001\n",
    "n_iter = 10000\n",
    "\n",
    "w = np.random.rand(tX.shape[1])\n",
    "for i in range(n_iter):\n",
    "    w, loss = learning_by_gradient_descent(y, tX, w, gamma)\n",
    "    if i % 100 == 0:\n",
    "        print(\"Current iteration={iter}, loss={l}\".format(iter=i, l=loss))\n",
    "print(w, loss)\n",
    "\n",
    "print(\"Accuracy from our code:\\n\")\n",
    "print(\"Logistic regression: \"+str(round(100*np.sum(predict_labels(w, tX)==y)/len(y),5))+\" %\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=15546.767300777186\n",
      "Current iteration=100, loss=3133.261547092958\n",
      "Current iteration=200, loss=3106.307115632103\n",
      "Current iteration=300, loss=3090.251614116\n",
      "Current iteration=400, loss=3080.6315599854674\n",
      "Current iteration=500, loss=3074.8327142736593\n",
      "Current iteration=600, loss=3071.3165266504634\n",
      "Current iteration=700, loss=3069.1722945593638\n",
      "Current iteration=800, loss=3067.857632509518\n",
      "Current iteration=900, loss=3067.0474982737655\n",
      "Current iteration=1000, loss=3066.5459049651554\n",
      "Current iteration=1100, loss=3066.2339808598604\n",
      "Current iteration=1200, loss=3066.0392197311457\n",
      "Current iteration=1300, loss=3065.9171603232758\n",
      "Current iteration=1400, loss=3065.840402446046\n",
      "Current iteration=1500, loss=3065.791981509788\n",
      "Current iteration=1600, loss=3065.7613486835776\n",
      "Current iteration=1700, loss=3065.741918395089\n",
      "Current iteration=1800, loss=3065.7295642195013\n",
      "Current iteration=1900, loss=3065.721691881364\n",
      "Current iteration=2000, loss=3065.7166653215813\n",
      "Current iteration=2100, loss=3065.713449849116\n",
      "Current iteration=2200, loss=3065.711389396562\n",
      "Current iteration=2300, loss=3065.710066980625\n",
      "Current iteration=2400, loss=3065.709216996195\n",
      "Current iteration=2500, loss=3065.708669921611\n",
      "Current iteration=2600, loss=3065.7083173601277\n",
      "Current iteration=2700, loss=3065.7080898816544\n",
      "Current iteration=2800, loss=3065.707942944697\n",
      "Current iteration=2900, loss=3065.7078479326756\n",
      "Current iteration=3000, loss=3065.707786435192\n",
      "Current iteration=3100, loss=3065.7077465928965\n",
      "Current iteration=3200, loss=3065.7077207572725\n",
      "Current iteration=3300, loss=3065.7077039900014\n",
      "Current iteration=3400, loss=3065.707693099257\n",
      "Current iteration=3500, loss=3065.707686019978\n",
      "Current iteration=3600, loss=3065.7076814148386\n",
      "Current iteration=3700, loss=3065.70767841702\n",
      "Current iteration=3800, loss=3065.7076764641843\n",
      "Current iteration=3900, loss=3065.7076751912327\n",
      "[-5.85999897e-01 -1.23514552e-01 -1.63051613e+00 -2.23113540e-01\n",
      "  6.14370471e-01  5.27740601e-01  3.94389604e-01 -7.80543971e-01\n",
      " -6.97540450e-02 -2.49049456e-01  4.37263471e-01 -8.80473744e-01\n",
      "  1.03969499e+00  5.31189507e-01  8.22447988e-01 -5.32627633e-02\n",
      " -2.20339170e-01 -1.94538280e-01 -8.03973473e-05 -7.76861435e-02\n",
      " -9.01221930e-02 -1.13648265e-01  3.28019971e-01  4.18704154e-01\n",
      "  1.16453040e-01 -2.91764587e-01 -2.66645423e-01 -3.48447143e-01\n",
      " -1.23322896e-01 -2.58720728e-01  3.35945091e-01] 3065.7076743676043\n",
      "After regularization: 67.14 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from reg_logistic_regression import *\n",
    "\n",
    "gamma = 0.0001\n",
    "lamda_ = 10\n",
    "n_iter = 4000\n",
    "\n",
    "w_reg = np.random.rand(tX.shape[1])\n",
    "for i in range(n_iter):\n",
    "    w_reg, loss = learning_by_penalized_gradient(y, tX, w_reg, gamma, lamda_)\n",
    "    if i % 100 == 0:\n",
    "        print(\"Current iteration={iter}, loss={l}\".format(iter=i, l=loss))\n",
    "print(w_reg, loss)\n",
    "\n",
    "print(\"After regularization: \"+str(round(100*np.sum(predict_labels(w_reg, tX)==y)/len(y),5))+\" %\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test = np.c_[np.ones((tX_test.shape[0], 1)), tX_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'test_reg_log_regr.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w_reg, tX_test)\n",
    "y_pred[np.where(y_pred == 0)] = -1\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
